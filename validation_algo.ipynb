{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "# dropped the train relevant column\n",
    "# as relevant and condition contains same infromation\n",
    "train = train.drop([\"Relevant?\"],axis=1)\n",
    "# dropped row with nan values\n",
    "train = train.dropna(axis=0,how='any')\n",
    "y_train = np.ravel(train[\"Condition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Statment     617\n",
       "Condition    617\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(dataset):\n",
    "    new_dataset = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for i in range(len(dataset)):\n",
    "        sent = dataset.loc[i,[\"Statment\"]].values[0].decode('utf-8')\n",
    "        sent = re.sub('[^a-zA-Z]', ' ', sent)\n",
    "        sent_token = sent.lower().split()\n",
    "        word_token = [word for word in sent_token if not word in stop_words]\n",
    "        stem = SnowballStemmer(\"english\")\n",
    "        # stem = PorterStemmer()\n",
    "        word_token = [stem.stem(word) for word in word_token]\n",
    "        cleaned_sent = \" \".join(word_token)\n",
    "        new_dataset.append(cleaned_sent)\n",
    "    return new_dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_preprocessing(train)\n",
    "# splitting the dataset into training and testing\n",
    "# (x,y) -> training\n",
    "# (xx,yy) -> testing\n",
    "x,xx,y,yy = train_test_split(x_train,y_train,test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(stop_words='english')\n",
    "train_tfidf=vectorizer.fit_transform(x)\n",
    "train_tfidf_array=train_tfidf.toarray()\n",
    "test_tfidf=vectorizer.transform(xx)\n",
    "test_tfidf_array=test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier\n",
    "clf_dt=DecisionTreeClassifier()\n",
    "clf_dt.fit(train_tfidf_array,y)\n",
    "prediction_dt = clf_dt.predict(test_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = clf_dt.score(test_tfidf_array,yy)\n",
    "loss = log_loss(yy, prediction_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 91.1290322581\n",
      "Loss : 3.06396240265\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : {}\".format(accuracy*100))\n",
    "print(\"Loss : {}\".format(loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
