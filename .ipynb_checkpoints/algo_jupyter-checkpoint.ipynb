{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train = train.drop([\"Relevant?\"],axis=1)\n",
    "train = train.dropna(axis=0,how='any')\n",
    "y_train = np.ravel(train[\"Condition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Statment    617\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(dataset):\n",
    "    new_dataset = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for i in range(len(dataset)):\n",
    "        sent = dataset.loc[i,[\"Statment\"]].values[0].decode('utf-8')\n",
    "        sent_token = sent.lower().split()\n",
    "        word_token = [word for word in sent_token if not word in stop_words]\n",
    "        stem = SnowballStemmer(\"english\")\n",
    "        # stem = PorterStemmer()\n",
    "        word_token = [stem.stem(word) for word in word_token]\n",
    "        cleaned_sent = \" \".join(word_token)\n",
    "        new_dataset.append(cleaned_sent)\n",
    "    return new_dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_preprocessing(train)\n",
    "x_test = data_preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(stop_words='english')\n",
    "train_tfidf=vectorizer.fit_transform(x_train)\n",
    "train_tfidf=tfidf.toarray()\n",
    "clf=RandomForestClassifier(max_depth=20,random_state=80)\n",
    "eq=clf.fit(train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    778\n",
       "1.0     14\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf=vectorizer.transform(x_test)\n",
    "test_tfidf_array=test_tfidf.toarray()\n",
    "# print(test_tfidf_array)\n",
    "prediction = eq.predict(test_tfidf_array)\n",
    "output = pd.DataFrame()\n",
    "output[\"Statment\"] = test[\"Statment\"]\n",
    "output[\"condition\"] = prediction\n",
    "output['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
