{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train = train.drop([\"Relevant?\"],axis=1)\n",
    "train = train.dropna(axis=0,how='any')\n",
    "y_train = np.ravel(train[\"Condition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Statment     617\n",
       "Condition    617\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(dataset):\n",
    "    new_dataset = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for i in range(len(dataset)):\n",
    "        sent = dataset.loc[i,[\"Statment\"]].values[0].decode('utf-8')\n",
    "        sent_token = sent.lower().split()\n",
    "        word_token = [word for word in sent_token if not word in stop_words]\n",
    "        stem = SnowballStemmer(\"english\")\n",
    "        # stem = PorterStemmer()\n",
    "        word_token = [stem.stem(word) for word in word_token]\n",
    "        cleaned_sent = \" \".join(word_token)\n",
    "        new_dataset.append(cleaned_sent)\n",
    "    return new_dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_preprocessing(train)\n",
    "x_test = data_preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(stop_words='english')\n",
    "train_tfidf=vectorizer.fit_transform(x_train)\n",
    "train_tfidf_array=train_tfidf.toarray()\n",
    "test_tfidf=vectorizer.transform(x_test)\n",
    "test_tfidf_array=test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "clf_rf=RandomForestClassifier(max_depth=20,random_state=80)\n",
    "clf_rf.fit(train_tfidf_array,y_train)\n",
    "prediction_rf = clf_rf.predict(test_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes classifier\n",
    "clf_nb=MultinomialNB()\n",
    "clf_nb.fit(train_tfidf_array,y_train)\n",
    "prediction_nb = clf_nb.predict(test_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier\n",
    "clf_dt=DecisionTreeClassifier()\n",
    "clf_dt.fit(train_tfidf_array,y_train)\n",
    "prediction_dt = clf_dt.predict(test_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting classifier\n",
    "clf = VotingClassifier(estimators=[('rf',clf_rf),('dt',clf_dt),('nb',clf_nb)],voting='soft')\n",
    "clf.fit(train_tfidf_array,y_train)\n",
    "prediction = clf.predict(test_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_tfidf_array)\n",
    "output = pd.DataFrame()\n",
    "output[\"Statment\"] = test[\"Statment\"]\n",
    "output[\"condition\"] = prediction_dt\n",
    "output['condition'].value_counts()\n",
    "output.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
